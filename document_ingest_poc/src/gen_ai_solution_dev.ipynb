{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcf03b66-e0ba-481d-a848-52f70e27e828",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "outputs": [],
   "source": [
    "# %skip\n",
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\",10)\n",
    "# %pip install chonkie --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "155c0117-66c9-4037-81e2-8c169b713fc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db8cec68-1327-48e6-bfad-6694dfe0b481",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE CATALOG dev_appian_poc;\n",
    "USE SCHEMA 02_gold;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ca04e9d-8e47-40c1-8342-4a70c182bf0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.table(\"document_text_contents\")\n",
    "# bronze_df = spark.table(\"dev_appian_poc.`00_bronze`.appian_raw_documents_ingest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aa2b1f4-32c0-4d2e-a7c3-a997f7c4ede5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_df = df.limit(1)\n",
    "test_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0616ec8e-e387-4c67-a84e-b936a96e180d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "outputs": [],
   "source": [
    "from chonkie import RecursiveChunker\n",
    "import pandas as pd\n",
    "from typing import Iterator\n",
    "from pyspark.sql.functions import pandas_udf, explode\n",
    "\n",
    "\n",
    "\n",
    "@pandas_udf(\"array<string>\")\n",
    "def read_as_chunk(batch_iter : Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    chunker = RecursiveChunker()\n",
    "    for batch in batch_iter:\n",
    "        result_chunk = []\n",
    "        for text in batch:\n",
    "            if text and isinstance(text, str):\n",
    "                chunks = chunker(text)\n",
    "                chunk_text = [str(chunk) for chunk in chunks]\n",
    "                result_chunk.append(chunk_text)\n",
    "            else:\n",
    "                result_chunk.append([])\n",
    "        yield pd.Series(result_chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bff9a4c6-9972-4e29-8114-962bc902e1f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_chunks = test_df.withColumn(\"full_text\", explode(read_as_chunk(\"full_text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5784b466-7b11-49a7-9a8b-9195bd7a6b07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_chunks.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a99030b-0dcf-41a4-9786-7e9b1712756e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "\n",
    "\n",
    "@pandas_udf(\"array<float>\")\n",
    "def get_embedding(contents: pd.Series, ) -> pd.Series:\n",
    "    deploy_client = get_deploy_client(\"databricks\")\n",
    "\n",
    "    def get_embeddings(batch):\n",
    "        response = deploy_client.predict(\n",
    "            endpoint=\"databricks-bge-large-en\", inputs={\"input\": batch}\n",
    "        )\n",
    "        return [e[\"embedding\"] for e in response.data]\n",
    "\n",
    "    batch_size = 150\n",
    "    batches = [\n",
    "        contents.iloc[i : i + batch_size]\n",
    "        for i in range(0, len(contents), batch_size)\n",
    "    ]\n",
    "\n",
    "    all_embeddings = []\n",
    "    for batch in batches:\n",
    "        all_embeddings += get_embeddings(batch.tolist())\n",
    "\n",
    "    return pd.Series(all_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6685b06-0d06-471e-b1ea-577d97b6c0f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_embedded = df_chunks.withColumn(\"embedding\", get_embedding(\"full_text\")).selectExpr(\n",
    "    \"row_num\", \"path\", \"full_text\", \"embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34d8075c-d2aa-451e-b3f1-0e53b28b74ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_embedded.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "chonkie==1.5.2"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4948919411074480,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "gen_ai_solution_dev",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
